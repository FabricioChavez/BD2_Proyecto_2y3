{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV con Ns diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo data1.csv creado con 2000 registros.\n",
      "Archivo data2.csv creado con 4000 registros.\n",
      "Archivo data3.csv creado con 8000 registros.\n",
      "Archivo data4.csv creado con 16000 registros.\n",
      "Archivo data5.csv creado con 32000 registros.\n",
      "Archivo data6.csv creado con 64000 registros.\n",
      "Archivo data7.csv creado con 128000 registros.\n"
     ]
    }
   ],
   "source": [
    "input_file = \"data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "Ns = [pow(2, i) * 1000 for i in [1, 2, 3, 4, 5, 6, 7]]\n",
    "\n",
    "for i, size in enumerate(Ns, start=1):\n",
    "    subset_df = df.head(size) \n",
    "    output_file = f\"data{i}.csv\"  \n",
    "    subset_df.to_csv(output_file, index=False) \n",
    "    print(f\"Archivo {output_file} creado con {size} registros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Spimi import SPIMIIndex\n",
    "\n",
    "# Uso del índice\n",
    "chunk_size = 10000  # Cantidad de filas por chunk\n",
    "memory_limit = 500000  # Límite de memoria en bytes\n",
    "\n",
    "# Función generadora para leer los archivos en chunks\n",
    "def document_chunks(file_path, chunk_size):\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        yield chunk[\"merge\"].dropna().tolist()\n",
    "\n",
    "# Eliminar archivos si existen\n",
    "def delete_previous_indices():\n",
    "    files_to_delete = [\"final_index.txt\", \"index_pointer.txt\"]\n",
    "    for file in files_to_delete:\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear Indices y Hacer Consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tiempos se toman solo en las consultas, no en la creacion del indice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tanjirou Kimetsu Nezuko\"\n",
    "topK = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando índice para data1.csv...\n",
      "Indexing...\n",
      "collection_size 2000\n",
      "Merging blocks...\n",
      "Índice creado para data1.csv.\n",
      "Query: ['tanjir', 'kimetsu', 'nezuko']\n",
      "\n",
      "\n",
      "1: 77.699 ms\n",
      "Creando índice para data2.csv...\n",
      "Indexing...\n",
      "collection_size 4000\n",
      "Merging blocks...\n",
      "Índice creado para data2.csv.\n",
      "Query: ['tanjir', 'kimetsu', 'nezuko']\n",
      "\n",
      "\n",
      "2: 116.502 ms\n",
      "Creando índice para data3.csv...\n",
      "Indexing...\n",
      "collection_size 8000\n",
      "Merging blocks...\n",
      "Índice creado para data3.csv.\n",
      "Query: ['tanjir', 'kimetsu', 'nezuko']\n",
      "\n",
      "\n",
      "3: 153.773 ms\n",
      "Creando índice para data4.csv...\n",
      "Indexing...\n",
      "collection_size 16000\n",
      "Merging blocks...\n",
      "Índice creado para data4.csv.\n",
      "Query: ['tanjir', 'kimetsu', 'nezuko']\n",
      "\n",
      "\n",
      "4: 275.077 ms\n",
      "Creando índice para data5.csv...\n",
      "Indexing...\n",
      "collection_size 32000\n",
      "Merging blocks...\n",
      "Índice creado para data5.csv.\n",
      "Query: ['tanjir', 'kimetsu', 'nezuko']\n",
      "\n",
      "\n",
      "5: 386.998 ms\n",
      "Creando índice para data6.csv...\n",
      "Indexing...\n",
      "collection_size 64000\n",
      "Merging blocks...\n",
      "Índice creado para data6.csv.\n",
      "Query: ['tanjir', 'kimetsu', 'nezuko']\n",
      "\n",
      "\n",
      "6: 613.799 ms\n",
      "Creando índice para data7.csv...\n",
      "Indexing...\n",
      "collection_size 70917\n",
      "Merging blocks...\n",
      "Índice creado para data7.csv.\n",
      "Query: ['tanjir', 'kimetsu', 'nezuko']\n",
      "\n",
      "\n",
      "7: 660.384 ms\n"
     ]
    }
   ],
   "source": [
    "# Crear índices para cada archivo generado\n",
    "for i in range(1, 8):  # Iterar por los nombres de los archivos generados\n",
    "\n",
    "    # Se eliminan el indice para la creacion del siguiente.\n",
    "    delete_previous_indices()\n",
    "\n",
    "    file_path = f\"data{i}.csv\"\n",
    "    print(f\"Creando índice para {file_path}...\")\n",
    "\n",
    "    # Inicializar el índice\n",
    "    index = SPIMIIndex(memory_limit=memory_limit)\n",
    "\n",
    "    # Construir el índice utilizando los chunks del archivo actual\n",
    "    index.construct_index(document_chunks(file_path, chunk_size))\n",
    "    print(f\"Índice creado para {file_path}.\")\n",
    "\n",
    "    # Iniciar Tiempo\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Se busca la query en el indice\n",
    "    query_index = index.retrieve_index(query)\n",
    "    data = dict(list(query_index.items())[:topK])\n",
    "\n",
    "    # Se comparan los resultados en el archivo csv\n",
    "    df = pd.read_csv(file_path)\n",
    "    results = [df.loc[doc_id, \"merge\"] for doc_id in list(query_index.keys())[:topK]]\n",
    "\n",
    "    # Finalizar Tiempo\n",
    "    end_time = time.time()\n",
    "    query_time = round((end_time - start_time) * 1000, 3)\n",
    "    print(f\"{i}: {query_time} ms\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
